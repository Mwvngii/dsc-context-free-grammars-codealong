


import nltk
nltk.download('punkt', quiet=True)
nltk.download('averaged_perceptron_tagger', quiet=True);


groucho_grammar = nltk.CFG.fromstring("""
S -> NP VP
PP -> P NP
NP -> Det N | Det N PP | 'I'
VP -> V NP | VP PP
Det -> 'an' | 'my'
N -> 'elephant' | 'pajamas'
V -> 'shot'
P -> 'in'
""")





parser = nltk.ChartParser(groucho_grammar)





sent = ['I', 'shot', 'an', 'elephant', 'in', 'my', 'pajamas']
for tree in parser.parse(sent):
    print(tree)





# Step 1
grammar = nltk.CFG.fromstring("""
S -> NP VP
PP -> P NP
NP -> Det N | Det N PP | 
VP -> V NP | VP PP
Det -> 'the'
Adj -> '100m'
N -> 'usain_bolt' | 'record' | 
V -> 'broke'
P -> 
""")


# Step 2
from nltk import word_tokenize
sent = 'usain_bolt broke the 100m record'


# Step 3
tokenized_sent = word_tokenize(sent)


# Step 4
parser = nltk.ChartParser(grammar)


# Step 5
for tree in parser.parse(tokenized_sent):
    print(tree)





grammar = nltk.CFG.fromstring("""
S -> NP VP
PP -> P NP
NP -> Det N PP | N | Det NP | Adj NP
VP -> V NP | VP PP
Det -> 'the'
Adj -> '100m'
N -> 'usain_bolt' | 'record' | 
V -> 'broke'
P -> 
""")


parser = nltk.ChartParser(grammar)


for tree in parser.parse(tokenized_sent):
    print(tree)





nltk.pos_tag(tokenized_sent)






